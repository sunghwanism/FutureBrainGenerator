{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchio as tio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, split_ratio=0.8):\n",
    "    datasets = df.Dataset.unique()\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    for dataset in datasets:\n",
    "        dataset_df = df[df['Dataset'] == dataset]\n",
    "        dataset_df = dataset_df.sample(frac=1).reset_index(drop=True) # shuffle\n",
    "        train_df = pd.concat([train_df, dataset_df.iloc[:int(len(dataset_df)*split_ratio)]])\n",
    "        test_df = pd.concat([test_df, dataset_df.iloc[int(len(dataset_df)*split_ratio):]])\n",
    "\n",
    "    train_df['mode'] = 'train'\n",
    "    test_df['mode'] = 'val'\n",
    "    print(f\"Total: {len(train_df)+len(test_df)} || Train Sample: {len(train_df)}, Test Sample: {len(test_df)}\")\n",
    "    merge_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.read_csv('/NFS/FutureBrainGen/data/long/long_old_HC_subj_phenotype_splited.csv')\n",
    "long_df.rename({\"SubID\":\"Subject\"}, inplace=True, axis=1)\n",
    "long_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_df = pd.read_csv('/NFS/FutureBrainGen/data/cross/cross_old_subj_phenotype_splited.csv')\n",
    "cross_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA for Cross Sectional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_df = pd.read_csv('/NFS/FutureBrainGen/data/cross/CrossSectional_included_file_v2.csv')\n",
    "hc_cross_df = cross_df[cross_df['Group'] == 'HC']\n",
    "hc_cross_df = hc_cross_df[hc_cross_df['Dataset'] != 'BGSP']\n",
    "hc_cross_df = hc_cross_df[hc_cross_df['Dataset'] != 'BNU']\n",
    "hc_cross_df = hc_cross_df[hc_cross_df['Dataset'] != 'RBP-L1']\n",
    "hc_cross_df = hc_cross_df[hc_cross_df['Age'] >= 40]\n",
    "hc_cross_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_cross_df.Dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hc_cross_df['Age'], bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited_hc_cross_df = split_train_test(hc_cross_df, 0.85)\n",
    "splited_hc_cross_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hc_cross_df.to_csv(\"/NFS/FutureBrainGen/data/cross/cross_old_subj_phenotype.csv\", index=False)\n",
    "# splited_hc_cross_df.to_csv(\"/NFS/FutureBrainGen/data/cross/cross_old_subj_phenotype_splited.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longitudinal EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.read_csv('/NFS/FutureBrainGen/data/long/long_phenotype_v2_clean_group.csv', index_col=0)\n",
    "hc_long_df = long_df[(long_df['Group_B'] == 'HC') & (long_df['Group_F'] == 'HC')]\n",
    "old_hc_long_df = hc_long_df[hc_long_df['Age_B'] >= 40]\n",
    "old_hc_long_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited_old_hc_long_df = split_train_test(old_hc_long_df, 0.94)\n",
    "splited2_old_hc_long_df = split_train_test(splited_old_hc_long_df[splited_old_hc_long_df['mode']=='train'], 0.94)\n",
    "splited2_old_hc_long_df_test = splited_old_hc_long_df[splited_old_hc_long_df['mode']=='val']\n",
    "splited2_old_hc_long_df_test['mode']='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited2_old_hc_long_df = pd.concat([splited2_old_hc_long_df, splited2_old_hc_long_df_test], axis=0)\n",
    "splited2_old_hc_long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splited2_old_hc_long_df.to_csv(\"/NFS/FutureBrainGen/data/long/long_old_HC_subj_phenotype_splited.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(old_hc_long_df['Age_B'], bins=10, alpha=0.7, color='navy', label='Baseline')\n",
    "plt.hist(old_hc_long_df['Age_F'], bins=10, alpha=0.7, color='orange', label='Follow-up')\n",
    "plt.text(85, 410, f\"Total Session: {len(old_hc_long_df)}\", fontsize=8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(1, 11, 1), old_hc_long_df['Interval'].value_counts().sort_index(),\n",
    "        edgecolor='black', color='skyblue', label='Interval')\n",
    "plt.xticks(np.arange(1, 11, 1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRIPATH = '/NFS/FutureBrainGen/data/long/down_img_1.7mm/'\n",
    "PHENO = '/NFS/FutureBrainGen/data/cross/CrossSectional_included_file.csv'\n",
    "MRILIST = os.listdir(MRIPATH)\n",
    "\n",
    "temp = MRILIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(MRIPATH + temp[0])\n",
    "img = img.get_fdata()\n",
    "\n",
    "# Convert the numpy array to a PyTorch tensor\n",
    "img_data = torch.from_numpy(img).float()\n",
    "img_data = img_data.unsqueeze(0)\n",
    "\n",
    "# Get the original dimensions (assumed to be 3D data)\n",
    "d, h, w = img_data.shape[1:]  # Shape without the channel\n",
    "\n",
    "# Define the target crop size\n",
    "target_d, target_h, target_w = (96, 112, 96)\n",
    "\n",
    "# Calculate the start and end indices for cropping (crop from the center)\n",
    "start_d = (d - target_d) // 2\n",
    "start_h = (h - target_h) // 2\n",
    "start_w = (w - target_w) // 2\n",
    "\n",
    "img_data = img_data[:, start_d:start_d + target_d, start_h:start_h + target_h, start_w:start_w + target_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Image Shape: \", img.shape)\n",
    "print(\"Cropped Image Shape: \", img_data[0].shape)\n",
    "print(target_d//2, target_h//2, target_w//2)\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].imshow(img_data[0, :, :, target_d//2])\n",
    "ax[1].imshow(img_data[0, target_h//2, :, :])\n",
    "ax[2].imshow(img_data[0, :, target_d//2, :])\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[2].set_xticks([])\n",
    "ax[2].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VQ-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_image(img):\n",
    "    origin = img['origin']\n",
    "    recon = img['recon']\n",
    "    if type(origin) == torch.Tensor:\n",
    "        origin = origin.cpu().detach().numpy()\n",
    "        \n",
    "    fig, ax = plt.subplots(2, 3, figsize=(8, 5))\n",
    "    ax[0, 0].imshow(origin[0][ :, :,54], cmap='gray')\n",
    "    ax[0, 1].imshow(np.rot90(origin[0][ :, 48, :]), cmap='gray')\n",
    "    ax[0, 2].imshow(np.rot90(origin[0][ 48, :, :]), cmap='gray')\n",
    "    ax[1, 0].imshow(recon[0][ :, :, 54], cmap='gray')\n",
    "    ax[1, 1].imshow(np.rot90(recon[0][ :, 48, :]), cmap='gray')\n",
    "    ax[1, 2].imshow(np.rot90(recon[0][ 48, :, :]), cmap='gray')\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            ax[i, j].set_xticks([])\n",
    "            ax[i, j].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'VQGAN'\n",
    "wandb_id = 'floral-field-2' # 'floral-field-2'  'dry-night-3'\n",
    "dim=8\n",
    "\n",
    "# img = np.load(f'/NFS/FutureBrainGen/results/{model}/img/{wandb_id}/img.npy')\n",
    "\n",
    "epoch = [100, 200, 300, 400 ,500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'VQGAN'\n",
    "# wandb_id = 'dry-night-3' # 'floral-field-2'  'dry-night-3'\n",
    "# dim=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in epoch:\n",
    "    print(f\"Epoch: {e}\")\n",
    "    img = np.load(f'/NFS/FutureBrainGen/results/{model}/img/{wandb_id}/recon_ep{e}_0_dim{dim}.npz')\n",
    "    viz_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_ldm_image(img, img_idx=0):\n",
    "\n",
    "    base, origin, recon, Age_B, Age_F, Sex = img['base_img'], img['follow_img'], img['synthetic_images'], img['Age_B'], img['Age_F'], img['Sex']\n",
    "\n",
    "    base = base.cpu().detach().numpy()\n",
    "    origin = origin.cpu().detach().numpy()\n",
    "    recon = recon.cpu().detach().numpy()\n",
    "        \n",
    "    fig, ax = plt.subplots(3, 3)\n",
    "\n",
    "\n",
    "    ax[0, 0].imshow(base[img_idx].squeeze()[:, :, 48], cmap='gray')\n",
    "    ax[0, 1].imshow(np.rot90(base[img_idx].squeeze()[:, 48, :]), cmap='gray')\n",
    "    ax[0, 2].imshow(np.rot90(base[img_idx].squeeze()[48, :, :]), cmap='gray')\n",
    "\n",
    "    ax[1, 0].imshow(origin[img_idx].squeeze()[:, :, 48], cmap='gray')\n",
    "    ax[1, 1].imshow(np.rot90(origin[img_idx].squeeze()[:, 48, :]), cmap='gray')\n",
    "    ax[1, 2].imshow(np.rot90(origin[img_idx].squeeze()[48, :, :]), cmap='gray')\n",
    "\n",
    "    ax[2, 0].imshow(recon[img_idx].squeeze()[:, :, 48], cmap='gray')\n",
    "    ax[2, 1].imshow(np.rot90(recon[img_idx].squeeze()[:, 48, :]), cmap='gray')\n",
    "    ax[2, 2].imshow(np.rot90(recon[img_idx].squeeze()[48, :, :]), cmap='gray')\n",
    "\n",
    "    ax[0,0].set_title(f\"(Base) Age: {Age_B[img_idx]} // Sex {Sex[img_idx]}\", fontsize=8)\n",
    "    ax[1,0].set_title(f\"(FU) Age: {Age_F[img_idx]} // Sex {Sex[img_idx]}\", fontsize=8)\n",
    "    ax[2,0].set_title(f\"(Recon) Age: {Age_F[img_idx]} // Sex {Sex[img_idx]}\", fontsize=8)\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            ax[i, j].set_xticks([])\n",
    "            ax[i, j].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model ='LDM'\n",
    "wandb_id = 'olive-deluge-4'\n",
    "epochs = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in epochs:\n",
    "    img = torch.load(f'/NFS/FutureBrainGen/results/{model}/img/{wandb_id}/{model}_ep{e}_dim16_{wandb_id}.pth')\n",
    "    viz_ldm_image(img, img_idx=0)\n",
    "    viz_ldm_image(img, img_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FutureBrainGen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
