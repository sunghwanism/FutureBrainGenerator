{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"/NFS/ADDiff/data/LDM\"\n",
    "IMGBASE = os.path.join(BASE, \"Image\")\n",
    "stat_pheno_df = pd.read_csv(os.path.join(BASE, 'phenotype', \"Longitudinal_data_BF_static.csv\"))\n",
    "covert_pheno_df = pd.read_csv(os.path.join(BASE, 'phenotype', \"Longitudinal_data_BF_converted.csv\"))\n",
    "images = os.listdir(IMGBASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_img_list = []\n",
    "with open(\"bad_qc_files_ldm.txt\", \"r\") as f:\n",
    "    bad_qc_files = f.readlines()\n",
    "    for i in bad_qc_files:\n",
    "        bad_img_list.append(i.strip().split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split(x):\n",
    "    return x.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_pheno_df['impath_B_split'] = stat_pheno_df['impath_B'].map(_split)\n",
    "stat_pheno_df['impath_F_split'] = stat_pheno_df['impath_F'].map(_split)\n",
    "covert_pheno_df['impath_B_split'] = covert_pheno_df['impath_B'].map(_split)\n",
    "covert_pheno_df['impath_F_split'] = covert_pheno_df['impath_F'].map(_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_stat_df = stat_pheno_df[~((stat_pheno_df['impath_B_split'].isin(bad_img_list)) | (stat_pheno_df['impath_F_split'].isin(bad_img_list)))]\n",
    "good_convert_df = covert_pheno_df[~((covert_pheno_df['impath_B_split'].isin(bad_img_list)) | (covert_pheno_df['impath_F_split'].isin(bad_img_list)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_convert_df.drop(columns=['impath_B_split', 'impath_F_split'], inplace=True)\n",
    "good_stat_df.drop(columns=['impath_B_split', 'impath_F_split'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_convert_df.to_csv(os.path.join(BASE, 'phenotype', \"Longitudinal_data_BF_converted_QC.csv\"), index=False)\n",
    "# good_stat_df.to_csv(os.path.join(BASE, 'phenotype', \"Longitudinal_data_BF_static_QC.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VQVAE QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"/NFS/ADDiff/data/vqvae\"\n",
    "IMGBASE = os.path.join(BASE, \"Image\")\n",
    "images = os.listdir(IMGBASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_img_list = []\n",
    "with open(\"bad_qc_files_vqvae_train.txt\", \"r\") as f:\n",
    "    bad_qc_files = f.readlines()\n",
    "    for i in bad_qc_files:\n",
    "        bad_img_list.append(i.strip().split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "oas_img_list = [im for im in bad_img_list if \"OAS4\" in im]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "OASPATH2 = '/NFS/MRI/OASIS_4/preprocess/cat12/Ses_2/mri/'\n",
    "OASPATH3 = '/NFS/MRI/OASIS_4/preprocess/cat12/Ses_3/mri/'\n",
    "OASPATH4 = '/NFS/MRI/OASIS_4/preprocess/cat12/Ses_4/mri/'\n",
    "OASPATH5 = '/NFS/MRI/OASIS_4/preprocess/cat12/Ses_5/mri/'\n",
    "\n",
    "OASPATH = [OASPATH2, OASPATH3, OASPATH4, OASPATH5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for OPATH in OASPATH:\n",
    "    for img in oas_img_list:\n",
    "        if os.path.exists(os.path.join(OPATH, img)):\n",
    "            print(os.path.join(BASE, \"Image\", 'train', img))\n",
    "            shutil.copy(os.path.join(OPATH, img), os.path.join(BASE, \"Image\", 'train', img))\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMGBASE =\"/NFS/ADDiff/data/vqvae/Image/train\"\n",
    "IMGBASE =\"/NFS/ADDiff/data/LDM/Image/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = os.listdir(IMGBASE)\n",
    "imgs.sort()\n",
    "imgs1 = imgs[:100]\n",
    "imgs2 = imgs[100:200]\n",
    "imgs3 = imgs[200:300]\n",
    "imgs4 = imgs[300:400]\n",
    "imgs5 = imgs[400:500]\n",
    "imgs6 = imgs[500:600]\n",
    "imgs7 = imgs[600:700]\n",
    "imgs8 = imgs[700:800]\n",
    "imgs9 = imgs[800:900]\n",
    "imgs10 = imgs[900:1000]\n",
    "imgs11 = imgs[1000:1100]\n",
    "imgs12 = imgs[1100:1200]\n",
    "imgs13 = imgs[1200:1300]\n",
    "\n",
    "img_list =  [imgs1, imgs2, imgs3, imgs4, imgs5, imgs6, imgs7, imgs8, imgs9, imgs10, imgs11, imgs12, imgs13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs in img_list:\n",
    "    fig, axs = plt.subplots(10, 10, figsize=(20, 20))\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            img = nib.load(os.path.join(IMGBASE, imgs[j*10+i]))\n",
    "            img = img.get_fdata()\n",
    "            axs[i][j].imshow(img[:,:,50], cmap='gray')\n",
    "            axs[i][j].axis('off')\n",
    "            axs[i][j].set_title(f'{imgs[j*10+i]}', fontsize=6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
